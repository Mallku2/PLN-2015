 * Ejercicio 1: Evaluación de Parsers
    Sobre lo ya implementado en eval.py, se agregó lo solicitado.
    La evaluación de los modelos "baseline" arrojó los siguientes resultados:

    _ FLAT:
        Parsed 3492 sentences

        Labeled
          Precision: 99.93%
          Recall: 14.57%
          F1: 25.43%

        Unlabeled
          Precision: 100.00%
          Recall: 14.58%
          F1: 25.45%

        real	0m5.495s
        user	0m5.472s
        sys	0m0.284s

    _ RBRANCH:
        Parsed 3492 sentences

        Labeled
          Precision: 8.81%
          Recall: 14.57%
          F1: 10.98%

        Unlabeled
          Precision: 8.87%
          Recall: 14.68%
          F1: 11.06%

        real	0m5.976s
        user	0m5.928s
        sys	0m0.312s

    _ LBRANCH:
        Parsed 3492 sentences

        Labeled
          Precision: 8.81%
          Recall: 14.57%
          F1: 10.98%

        Unlabeled
          Precision: 14.71%
          Recall: 24.33%
          F1: 18.33%

        real	0m6.263s
        user	0m6.216s
        sys	0m0.324s


 * Ejercicio 2: Algoritmo CKY
    Se implementó el algoritmo CKY, siguiendo las sugerencias de las filminas
de Collins, junto con la utilización de un diccionario que hace de "cache" de
producciones, para poder obtener la información de las mismas de manera más
ágil.
    Se agregó, a la suite de tests, un caso de una oración con más de un
análisis posible. La oración se extrajo de la videolecture "Examples of
Ambiguity", del ejemplo sobre "POS ambiguity", referido a la palabra
inglesa "duck", la cual puede ocurrir como verbo o sustantivo. De allí que
pueda existir más de un análisis, en una oración que la incluya. La oración
bajo análisis es 'the girl saw her duck with the telescope', y para analizarla
se definió la siguiente PCFG, en donde las probabilidades se asignaron de
manera arbitraria:

                S -> NP VP              [1.0]

                VP -> VP PP             [0.25]
                VP -> Vt NP             [0.25]
                VP -> V S               [0.25]
                VP -> Vi                [0.25]

                NP -> PRP NN            [0.5]
                NP -> Det Noun          [0.25]
                NP -> 'her'             [0.25]

                PP -> IN NP             [1.0]

                Vi -> 'duck'            [1.0]

                IN -> 'with'            [1.0]

                Det -> 'the'            [1.0]

                Noun -> 'girl'          [0.25]
                Noun -> 'telescope'     [0.75]

                Vt -> 'saw'             [1.0]

                PRP -> 'her'            [1.0]

                NN -> 'duck'            [1.0]

 * Ejercicio 3: PCFGs No Lexicalizadas
    Se implementó una PCFG no lexicalizada. El código resultante es sucinto,
gracias a los métodos que provee la clase Tree y procedimientos del módulo
nltk.grammar (que nos permiten obtener una PCFG en base a las producciones
ordinarios extraidas del corpus).
    Se entrenó el modelo resultante, y se lo evaluó sobre la misma porción
del corpus utilizada en el ejercicio 2. Obtuvimos los siguientes resultados:

        Labeled
          Precision: 71.10%
          Recall: 70.41%
          F1: 70.76%
        Unlabeled
          Precision: 73.06%
          Recall: 72.35%
          F1: 72.71%

        real    1m47.062s
        user    1m43.904s
        sys 0m0.404s

 * Ejercicio 4: Markovización Horizontal
    Se modificó la UPCFG, para agregar la posibilidad de utilizar
markovización horizontal (MH). La implementación simplemente se apoya en el
método chomsky_normal_form de la clase Tree, el cual, opcionalmente, puede
realizar este trabajo.
    Se evaluaron modelos con MH de orden n variable, entre 0 y 4, sobre la
misma porción de corpus empleada para evaluar los modelos anteriores.
Obtuvimos los siguientes resultados:

    _ MH = 0:
        Labeled
          Precision: 65.94%
          Recall: 63.54%
          F1: 64.72%
        Unlabeled
          Precision: 67.62%
          Recall: 65.16%
          F1: 66.36%

        real    0m42.093s
        user    0m41.196s
        sys 0m0.400s

    _ MH = 1:
        Labeled
          Precision: 71.32%
          Recall: 71.38%
          F1: 71.35%
        Unlabeled
          Precision: 72.86%
          Recall: 72.92%
          F1: 72.89%

        real    0m49.415s
        user    0m48.076s
        sys 0m0.392s

    _ MH = 2:
        Labeled
          Precision: 73.38%
          Recall: 72.43%
          F1: 72.90%
        Unlabeled
          Precision: 75.02%
          Recall: 74.05%
          F1: 74.53%

        real    1m5.575s
        user    1m4.068s
        sys 0m0.452s

    _ MH = 3:
        Labeled
          Precision: 74.05%
          Recall: 72.43%
          F1: 73.23%
        Unlabeled
          Precision: 75.87%
          Recall: 74.21%
          F1: 75.03%

        real    1m9.332s
        user    1m7.340s
        sys 0m0.852s

    _ MH = 4:
        Labeled
          Precision: 71.77%
          Recall: 70.90%
          F1: 71.33%
        Unlabeled
          Precision: 73.65%
          Recall: 72.76%
          F1: 73.20%

        real    1m16.698s
        user    1m15.224s
        sys 0m0.492s
